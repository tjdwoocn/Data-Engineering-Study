{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 엔지니어링\n",
    "\n",
    "## 데이터 엔지니어링의 필요성\n",
    "> 문제를 해결하기 위한 가설 검증 단계\n",
    "\n",
    "![ss](./DE_img/screenshot05.png)\n",
    "- 모든 비지니스가 동일한 데이터 분석 환경을 갖출 수가 없으며\n",
    "- 성장 단계에 따라 선택, 집중해야 하는 분석 환경이 다름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot06.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot07.png)\n",
    "- 단순 하나의 소스에서의 데이터를 분석하고 끝내는 것이 아니라\n",
    "- 여러 환경/소스의 데이터를 통합적으로 관리/분석 하여 좀더 나은 전략을 수립하는 것\n",
    "- 또는 그렇게 하기 위한 노력이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot08.png)\n",
    "- 지속적인 성장이 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 아키텍처\n",
    "> 데이터 아키텍처를 구성하기 위해 고려할 사항들에 대한 고민이 반드시 필요"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot09.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot10.png)\n",
    "- 원칙: 유지,관리, 보안, 품질 등에 대한 원칙\n",
    "- 조직: 어떻게 누가 관리? 방법은?\n",
    "- 프로세스: 관리를 위한 시스템"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot11.png)\n",
    "- 문제가 생겼을때 적절한 해결방안 마련\n",
    "- 새로운 기술 쉽게 적용이 가능하도록"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot12.png)\n",
    "- 실시간 데이터 핸들링\n",
    "- 자동화/스케줄러"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 시큐리티\n",
    "- 내부와 외부 모든 곳에서부터 발생할 수 있는 위험 요소들을 파악\n",
    "- 어떻게 데이터를 안전하게 관리할 수 있는지 아키텍쳐 안에 포함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 셀프 서비스 환경 구축\n",
    "![ss](./DE_img/screenshot13.png)\n",
    "- 확장성!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 시스템의 옵션들\n",
    "> API! 다양한 데이터에 접근 가능하도록 만들어진 송신방법!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API의 시대\n",
    "![ss](./DE_img/screenshot14.png)\n",
    "- 데이터를 주고 받을 수 있는 환경/생태계 구축"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Database (관계형 데이터베이스)\n",
    "![ss](./DE_img/screenshot15.png)\n",
    "- 데이터 저장의 목적\n",
    "- SQL: 자료 열람 및 유지\n",
    "- MySQL, OracleDB 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NoSQL \n",
    "![ss](./DE_img/screenshot16.png)\n",
    "- 기존 RDBMS의 대용량, 형식이 없는 데이터 처리의 한계\n",
    "- 주로 메신저에서 사용됨 (KakaoTalk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hadoop/Spark/Presto 등 빅데이터 처리\n",
    "![ss](./DE_img/screenshot17.png)\n",
    "- 분산/병렬 처리\n",
    "- 데이터 분석/엔지니어링 분야에서 많이 쓰이는 Spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serverless Framework\n",
    "![ss](./DE_img/screenshot18.png)\n",
    "- 기존에 유지/관리/보수 에 불편함이 많던 서버\n",
    "- 트리거 처리에 용이한 서버리스!\n",
    "- 사용한 만큼만 결제, 몇건의 처리건 같은 속도로\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline\n",
    "> 데이터를 한 장소에서 다른 장소로 옮기는 것을 의미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 파이프라인이 필요한 경우\n",
    "![ss](./DE_img/screenshot19.png)\n",
    "- 다양한 소스로 부터 데이터 획득\n",
    "- 데이터 사일로와 같이 데이터가 각 영역에만 고립되어 있는경우 통합이 필요함\n",
    "- 실시간 분석!\n",
    "- 클라우드 환경에서의 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 파이프라인의 예시\n",
    "![ss](./DE_img/screenshot20.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 파이프라인 구축시 고려 사항\n",
    "![ss](./DE_img/screenshot21.png)\n",
    "- Scalability: 데이터의 양, 소스가 10개, 100개, 1000개 등으로 늘어날때\n",
    "- Stability: 안정성, 에러 핸들링\n",
    "- Security: 데이터 이동간 보안, 리스크 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 자동화의 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ss](./DE_img/screenshot22.png)\n",
    "- ETL (추출, 수집, 정제) 하는 프로세싱을 자동화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자동화시 고려할 사항\n",
    "- 데이터 프로세싱 스텝들 (어떤 API?, 어떤 알고리즘으로? 시각화는?)\n",
    "- 에러 핸들링 및 모니터링 (에러 생성시 대처방안, 재시도는 몇번?)\n",
    "- 트리거 / 스케쥴링 (퍼포먼스, 하루에 몇번?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 프로세싱 스텝들\n",
    "![ss](./DE_img/screenshot23.png)\n",
    "예) \n",
    "1. Source 데이터베이스로부터 Amason S3로 데이터 가져옴\n",
    "2. Data Validater에서 데이터의 품질 체크\n",
    "3. 확인된 데이터는 다른 S3에 적재\n",
    "4. EMR ETL Cluster 에서 데이터 정제 등을 시행\n",
    "5. 정제된 데이터를 다시 S3에 적재\n",
    "6. Redshift라고하는 분석에 맞춰진 데이터베이스 로더에 넣어 작동\n",
    "7. DynamoDB 등에 분산 저장/사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 에러 핸들링 및 모니터링\n",
    "![ss](./DE_img/screenshot24.png)\n",
    "- logging 이라는 python 패키지 사용\n",
    "- 로깅을 활용해 에러 발생시 문자, slack, 메세지 등으로 알림받음\n",
    "- 클라우드 안에서도 쉽게 관리가능토록 만들어짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 트리거 & 스케줄링\n",
    "![ss](./DE_img/screenshot25.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔드 투 엔드 아키텍쳐"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 빅데이터 처리를 위한 데이터 레이크\n",
    "- 데이터 웨어하우스를 넘어 데이터 레이크로\n",
    "- 하나 - 하나 씩 연결되는 것이 아니라 다양한 파트에서 공유 및 공동처리\n",
    "    - 각종 소스로부터 다양한 데이터를 Amazon S3에 저장\n",
    "    - 스파크와 Amazon EMR(데이터 처리에 특화된)에서 전처리\n",
    "    - Amazon Redshift(RDB) 에서 대용량의 데이터를 처리(분석 등)\n",
    "    - Athena와 RDS 등에서 2차 처리\n",
    "    - 마지막으로 Reporting(시각화 등)\n",
    "![ss](./DE_img/screenshot26.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 넷플릭스 데이터 시스템 예시\n",
    "![ss](./DE_img/screenshot27.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 우버 데이터 아키텍처\n",
    "![ss](./DE_img/screenshot28.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spotify 프로젝트 아키텍처\n",
    "> 우리가 만들게될 Spotify 아키텍처에 대해 알아볼것임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ad hoc VS Automated\n",
    "- Ad hoc: 쓰고 싶을때마다 사용 가능한 분석 환경 구축, 분석 환경이 빠르게 변할 수 있는\n",
    "    - 혼자만이 아닌, 여러 인원이 다양한 분석을 하기 위한\n",
    "    - 자동화를 위한 이니셜 데이터가 필요\n",
    "- Automated: 언제 어느 이벤트가 생길지 모르는 환경에서 실시간으로 트리거를 통해 자동화 시스템 구축\n",
    "![ss](./DE_img/screenshot29.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아티스트 관련 데이터 수집 프로세스\n",
    "- 기존에 정보가 없는 unknown 아티스트의 정보가 들어오면\n",
    "- Serverless lambda(event/trigger)에서 spotify api 가 해당 정보를 가지고 있는지 확인\n",
    "- 있다면 우리의 데이터 베이스에 해당 정보들을 불러와서 저장\n",
    "- 각각의 데이터베이스는 다른 목적을 가지고 작동\n",
    "- Ad hoc data job 에서는 처음에 데이터베이스 구축을 할 떄 사용\n",
    "![ss](./DE_img/screenshot30.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 분석 환경 구축\n",
    "- 데이터를 어떻게 분석/사용 할 것 인지에 대한 환경 구축\n",
    "![ss](./DE_img/screenshot31.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 서비스 관련 데이터 프로세스\n",
    "![ss](./DE_img/screenshot32.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
